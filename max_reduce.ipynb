{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nonG0RNYbkhf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03a42367-aeb2-490e-c96a-294c9bef7fb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version  # correct double dash\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9gGnmO4btFn",
        "outputId": "91142379-41fa-41ff-a352-6db11f727ec9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-nnyujwr3\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-nnyujwr3\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 28f872a2f99a1b201bcd0db14fdbc5a496b9bfd7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.2.1-py3-none-any.whl size=10742 sha256=fdb30b442a03a2b978d94f242f4f3839c3b517111d4c5bcc31496f40b5aacbba\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bo6jvgnk/wheels/ef/1d/c6/f7e47f1aa1bc9d05c4120d94f90a79cf28603ef343b0dd43ff\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHNkt6_XbyPh",
        "outputId": "4b569fbe-901e-402b-ecf9-e50dc8d0306f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpovpbgvyo\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code = r'''\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "__global__ void maxReduce(int* input) {\n",
        "    int tid = threadIdx.x;\n",
        "    int step_size = 1;\n",
        "    int num_threads = blockDim.x;\n",
        "\n",
        "    while (num_threads > 0) {\n",
        "        if (tid < num_threads && (tid * step_size * 2 + step_size) < blockDim.x * 2) {\n",
        "            int fst = tid * step_size * 2;\n",
        "            int snd = fst + step_size;\n",
        "            if (input[fst] < input[snd]) {\n",
        "                input[fst] = input[snd];\n",
        "            }\n",
        "        }\n",
        "        __syncthreads();\n",
        "        step_size <<= 1;\n",
        "        num_threads >>= 1;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int count = 8;\n",
        "    const int size = count * sizeof(int);\n",
        "    int h[count] = {13, 65, 15, 14, 33, 2, 30, 8};\n",
        "\n",
        "    int* d;\n",
        "    cudaMalloc(&d, size);\n",
        "    cudaMemcpy(d, h, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    maxReduce<<<1, count / 2>>>(d);\n",
        "\n",
        "    int result;\n",
        "    cudaMemcpy(&result, d, sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    printf(\"Largest number is at index: %d\\n\", result);\n",
        "\n",
        "    cudaFree(d);\n",
        "    return 0;\n",
        "}\n",
        "'''\n",
        "\n",
        "with open('max_reduce.cu', 'w') as f:\n",
        "    f.write(code)\n"
      ],
      "metadata": {
        "id": "FWIg984ab6jO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc max_reduce.cu -o max_reduce"
      ],
      "metadata": {
        "id": "nVp_nxG3cZDH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./max_reduce"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L82vh4cDcbhz",
        "outputId": "dbb43c37-1e81-4470-a477-f352eec20b9c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Largest number is at index: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LHv9ARR1ce5y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}